---
title: "Methodology"
output: 
  html_document:
    theme: cerulean
---

<style type="text/css">
body { 
  font-size: 16px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = T, resuts = F, fig.align = 'center')
```


Yapa is a simple poll aggregator that combines polls with previous election results to estimate  state-level support for US presidential candidates and simulate potential electoral college outcomes.

Yapa starts with previous election results as a baseline estimate for candidate support in each state.  As state and national polling data become available it updates that estimate, adjusting for poll sample size and recency, and accounting for swings in the national popular vote.  In states with few recent polls, or many polls with very different results, there will be considerable uncertainty around these poll averages.  In states with many recent polls that mostly agree, the uncertainty will be lower.

Once it has estimated poll averages, Yapa then runs tens of thousands of simulations to generate distributions for national and state-level support for each candidate.  In each simulation, it considers the possibility of systematic polling error — e.g., state polls underestimate support for the Democrat by 1% on average — and generates an election result based on that possibility.  The estimates for systematic error are based on their historical distributions, and are rarely outside the range of 1-2%.  However, if poll averages in many states are close, that systematic polling error can be an important factor in the outcome. 

# Model

Yapa models support for each presidential candidate with three layers:

1) **Prior**: the results from the previous general election at the state and national level, and parameters for the distribution of state and national polling misses from the previous five presidential elections;
2) **Data**: state-level and national polls, weighted by recency and sample size;
3) **Non-sampling error**: systematic polling error based on its historical distribution.

Specifically, the number of respondents that support each candidate in each poll $y_{p, c}$ is drawn from the total respondents in that poll $n_p$ at a candidate and state (S) or national (N) specific polling average $\theta_{s, c}$.  The polling averages follow a normal model centered on the national average for each candidate plus the lean for each candidate in each state.  In the absence of state level polling, the national average plus the state lean stands in as the best available estimate. 

$$
\begin{align}
y_{p, c} &\sim Binomial(n_p, \theta^S_{s, c}) \\
\theta^S_{s, c} &\sim Normal(\theta^N_c + \pi_{s,c}, \tau) \\
\pi_{s, c} &\sim Normal(\beta_c\times p_{s, c}) \\
\end{align}
$$

To simulate outcomes, we first estimate the distribution of "misses" for each candidate at the state and national level, based on the last five presidential elections.  Since state poll misses tend to be correlated, we first sample a national miss, then sample results for each state based on the national miss and state-specific errors.

$$
\begin{align}
\mu_{s, c} &\sim Normal(\theta^S_{s, c} + \epsilon_c, \sigma_s) \\
\epsilon &\sim MultiNormal(M, \Sigma)
\end{align}
$$


All code and data are available at [github.com/alexpavlakis/yapa](https://github.com/alexpavlakis/yapa).  Polls are pulled from [538](https://projects.fivethirtyeight.com/polls) and [RealClearPolitics](https://www.realclearpolitics.com/epolls/latest_polls/).

## Weighting 

Polls tend to contribute more to final inferences if they have a) larger sample sizes and b) are closer to the election. We discount polls by recency according to the exponential decay model:

$$
discount_p = e^\frac{-days\_out_p}{\gamma}
$$

```{r fig.align='center', echo = F}
days <- seq(0, 365, 1)
wt <- exp(-days/40)

par(las = 1, mar = c(4, 4, 1, 1))
plot(days, wt, type = "l", bty = 'n', xaxt = 'n',
     xlab = "days from election", ylab = "discount factor",
     main = NULL)
axis(1, at = seq(0, 300, 30))
```

A rough rule of thumb is that a poll seven days from the election will get about twice as much weight as a poll seven weeks from the election.  Polls more than three months out get very little weight, and will contribute little to inferences when there are polls closer to the election.
