---
title: "Methodology"
output: 
  html_document:
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = T, resuts = F, fig.align = 'center')
```


Yapa is a simple poll aggregator that estimates state-level support for US presidential candidates by combining state-level polls with previous election results.  It relies only on polling data and prior election results, not economic or demographic indicators, since any impact these have on results will materialize in polls before the election.  Its strength is appropriate handling of uncertainty.  80% intervals are calibrated to include 80% of results in previous presidential elections.

# Model

We model state level support for each presidential candidate with three layers:

1) **Prior**: the results in that state from the previous general election, adjusted by partisan swings between previous national election results and current national polls;
2) **Data**: state-level polls, weighted by recency and sample size;
3) **Non-sampling error**: polling error based on its historical distribution, allowing for correlated errors across states.

Specifically, the number of respondents that support each candidate in each poll $y_{p, c}$ is drawn from the total respondents in that poll $n_p$ at a rate specific to the candidate and the state $\theta_{s, c}$.  The rate parameters are distributed with a candidate-state specific center $\alpha_{c, s}$.  The sum of proportions for each candidate must equal one.  Finally, to simulate true underlying support, we first sample a vector of *biases* for each candidate, then sample support based on each state's rate parameter and the sampled bias.  These simulations are repeated tens of thousands of times.

$$
\begin{align}
y_{p, c} &\sim Binomial(n_p, \theta_{s, c}) \\
\theta_{s, c} &\sim Student\_t(\nu, \alpha_{s, c}, \tau) \\
\sum_c \theta_s &= 1 
\end{align}
$$

All code and data are available at [github.com/alexpavlakis/yapa](https://github.com/alexpavlakis/yapa).

## Weighting 

Polls tend to contribute more to final inferences if they have a) larger sample sizes and b) are closer to the election. We discount polls by recency according to the exponential decay model:

$$
discount_p = e^\frac{-days\_out_p}{\gamma}
$$

```{r fig.align='center', echo = F}
days <- seq(0, 365, 1)
wt <- exp(-days/40)

par(las = 1, mar = c(4, 4, 1, 1))
plot(days, wt, type = "l", bty = 'n', 
     xlab = "days from election", ylab = "discount factor",
     main = NULL)
```


```{r plot, eval = FALSE}
library(tidyverse)
load("../results/ppc16")

# Plot
ppc16 %>%
  ggplot() +
  aes(x = mean, y = dem, xmin = lower, xmax = upper, 
      label = abb, col = dem) + 
  geom_abline(intercept = 0, slope = 1, lty = 2, col = 'darkgrey') +
  geom_point(alpha = 0.8, cex = 0.7) +  
  geom_errorbarh(height = 0, alpha = 0.7, lwd = 0.4) +
  ggrepel::geom_text_repel(size = 3, lwd = 0.4) +
  scale_color_gradient(low = "red", high = "blue") +
  scale_x_continuous(limits = c(0, 1),
                     labels = paste0(seq(0, 100, 25), "%")) +
  scale_y_continuous(limits = c(0, 1),
                     labels = paste0(seq(0, 100, 25), "%")) +
  guides(col = F) +
  theme_minimal() +
  labs(x = "prediction", y = "result",
       title = "Model predictions and election results: 2016") +
  theme(plot.title = element_text(size = 15, face = "bold")) 

```

```{r table, eval = FALSE}
ppc16 %>%
  select(state, `lower prediction` = lower,
         prediction = mean, `upper prediction` = upper, 
         result = dem) %>%
  mutate_if(is.numeric, function(x) paste0(round(x*100, 1), "%")) %>%
  DT::datatable(., options = list(scrollX = TRUE, 
                                  scrollY = "200px",
                                  pageLength = 51))

```

